{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3828a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#定义训练集测试集的划分函数\n",
    "def split_train_test(data, p_train, mode = \"random\",seed = 0, SavePath=\"\", replace=False): \n",
    "    #输入pandas数组和训练集比例,mode为划分方式，seed为随机模式下的随机数种子，0代表不设种子\n",
    "    #SavePath为文件保存路径，在replace=False的情况下，如果对应文件夹下已经存在名为train.csv及test.csv的文件则不保存\n",
    "    if mode == \"random\":  #随机划分\n",
    "        if seed != 0 : \n",
    "            np.random.seed(seed)\n",
    "        nrand = np.random.rand(data.shape[0])\n",
    "        data_train = data[nrand<p_train] #以p的概率进入训练集\n",
    "        data_test = data[nrand>p_train]  #以1-p的概率进入测试集\n",
    "    else:      #从中间切分为两部分作为训练集和测试集\n",
    "        cut = int(p_train * data.shape[0])\n",
    "        data_train = data[0:cut]\n",
    "        data_test = data[cut+1:data.shape[0]]\n",
    "    \n",
    "    if (replace == True) or not os.path.exists(SavePath+\"train.csv\") or not os.path.exists(SavePath+\"test.csv\"):\n",
    "        data_train.to_csv(SavePath+\"train.csv\",index=None)\n",
    "        data_test.to_csv(SavePath+\"test.csv\",index=None)\n",
    "    return (data_train, data_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb3d89e",
   "metadata": {},
   "source": [
    "读取数据csv文件并且划分训练集和测试集，然后保存到train.csv和test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "379c4b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 172\n",
      "Test data size: 61\n"
     ]
    }
   ],
   "source": [
    "SavePath=\"C:/Users/Administrator/program/data/\"\n",
    "\n",
    "path1=\"C:/Users/Administrator/program/data/data1/\"\n",
    "data1 = pd.read_csv(path1+\"part1.csv\") \n",
    "data1[\"source\"]=\"data1/\"   #标注数据源\n",
    "\n",
    "\n",
    "(data_train1,data_test1)=split_train_test(data1, 0.7 , mode = \"random\", SavePath=SavePath , seed=123)   #7:3划分训练集和测试集,使用随机数种子固定结果\n",
    "print(\"Train data size:\",data_train1.shape[0])\n",
    "print(\"Test data size:\",data_test1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff5aed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 162\n",
      "Test data size: 67\n"
     ]
    }
   ],
   "source": [
    "path2=\"C:/Users/Administrator/program/data/data2/\"\n",
    "data2 = pd.read_csv(path2+\"part2.csv\") \n",
    "data2[\"source\"]=\"data2/\"   #标注数据源\n",
    "\n",
    "\n",
    "(data_train2,data_test2)=split_train_test(data2, 0.7 , mode = \"random\", SavePath=SavePath )   #7:3划分训练集和测试集,已使用过随机数种子不重新设置\n",
    "print(\"Train data size:\",data_train2.shape[0])\n",
    "print(\"Test data size:\",data_test2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f25e8f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 164\n",
      "Test data size: 79\n"
     ]
    }
   ],
   "source": [
    "path3=\"C:/Users/Administrator/program/data/data3/\"\n",
    "data3 = pd.read_csv(path3+\"part3.csv\") \n",
    "data3[\"source\"]=\"data3/\"   #标注数据源\n",
    "\n",
    "\n",
    "(data_train3,data_test3)=split_train_test(data3, 0.7 , mode = \"random\", SavePath=SavePath )   #7:3划分训练集和测试集,已使用过随机数种子不重新设置\n",
    "print(\"Train data size:\",data_train3.shape[0])\n",
    "print(\"Test data size:\",data_test3.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444661cd",
   "metadata": {},
   "source": [
    "由于本试验需要用将三个文件夹的数据一起使用，因此需要将数据合并重新生成新的文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45925b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 498\n",
      "Test data size: 207\n"
     ]
    }
   ],
   "source": [
    "train=pd.concat([data_train1,data_train2,data_train3])\n",
    "test=pd.concat([data_test1,data_test2,data_test3])\n",
    "\n",
    "train.to_csv(SavePath+\"train.csv\",index=None)\n",
    "test.to_csv(SavePath+\"test.csv\",index=None)\n",
    "print(\"Train data size:\",train.shape[0])\n",
    "print(\"Test data size:\",test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74cfb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
